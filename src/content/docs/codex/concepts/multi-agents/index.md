---
title: '멀티 에이전트'
description: 'Codex는 전문화된 에이전트를 병렬로 생성하고 결과를 하나의 응답으로 모아 멀티 에이전트 워크플로를 실행할 수 있습니다.'
---

Source URL: https://developers.openai.com/codex/concepts/multi-agents

# 멀티 에이전트

Codex는 전문화된 에이전트를 병렬로 생성하고 결과를 하나의 응답으로 모아 멀티 에이전트 워크플로를 실행할 수 있습니다.

이 페이지에서는 핵심 개념과 고려사항을 설명합니다. 설정, 에이전트 구성, 예시는 [Multi-agents](https://developers.openai.com/codex/multi-agent)를 참조하세요.

## 멀티 에이전트 워크플로가 도움이 되는 이유

큰 컨텍스트 창을 사용해도 모델에는 한계가 있습니다. 요구사항, 제약조건, 결정사항을 정의하는 메인 대화에 탐색 노트, 테스트 로그, 스택 트레이스, 명령 출력 같은 시끄러운 중간 결과를 쏟아붓는다면 세션 전반의 신뢰성이 떨어질 수 있습니다.

이런 현상은 종종 이렇게 설명됩니다:

- **컨텍스트 오염**: 유용한 정보가 시끄러운 중간 결과 아래에 묻힙니다.
- **컨텍스트 부패**: 관련성이 떨어지는 세부사항으로 대화가 채워지면서 성능이 저하됩니다.

배경 지식은 Chroma의 [context rot](https://research.trychroma.com/context-rot) 설명을 참고하세요.

멀티 에이전트 워크플로는 시끄러운 작업을 메인 스레드에서 분리함으로써 도움이 됩니다:

- **메인 에이전트**는 요구사항, 결정, 최종 출력에 집중하도록 유지합니다.
- **하위 에이전트**는 탐색, 테스트, 로그 분석 등 특정 작업을 위해 병렬로 실행합니다.
- **요약**을 하위 에이전트가 메인 에이전트에게 전달하고, 원시 중간 출력은 보내지 않습니다.

출발점으로 읽기 중심 작업(탐색, 테스트, 분류, 요약)에 병렬 에이전트를 사용하는 것이 좋습니다. 여러 에이전트가 동시에 코드를 수정하는 쓰기 중심 병렬 워크플로는 충돌과 조정 비용이 커질 수 있으므로 더 신중히 접근하세요.

## 핵심 용어

Codex는 멀티 에이전트 워크플로에서 몇 가지 관련 용어를 사용합니다:

- **멀티 에이전트**: Codex가 여러 에이전트를 병렬로 실행하고 결과를 결합하는 워크플로.
- **하위 에이전트**: Codex가 특정 작업을 처리하도록 시작한 위임된 에이전트.
- **에이전트 스레드**: `/agent`로 점검하거나 전환할 수 있는 에이전트의 CLI 스레드.

## 모델 및 추론 선택

에이전트마다 다른 모델 및 추론 설정이 유리할 수 있습니다.

`gpt-5.3-codex-spark`는 ChatGPT Pro 구독자를 위한 리서치 프리뷰로 제공됩니다. 현재 가용성은 [Models](https://developers.openai.com/codex/models)을 참고하세요. API를 통해 Codex를 사용하는 경우엔 오늘날 GPT-5.2-Codex를 사용하세요.

### 모델 선택

- **`gpt-5.3-codex`**: 코드 리뷰, 보안 분석, 여러 단계 구현 또는 요구사항이 모호한 작업처럼 강한 추론이 필요한 에이전트에 사용하세요. 메인 에이전트와 수정 제안 또는 적용을 하는 에이전트가 여기에 해당합니다.
- **`gpt-5.3-codex-spark`**: 탐색, 읽기 중심 스캔, 빠른 요약 작업처럼 속도를 우선하는 에이전트에 사용하세요. Spark는 메인 에이전트에 정제된 결과를 되돌리는 병렬 작업자에 적합합니다.

### 추론 노력(`model_reasoning_effort`)

- **`high`**: 에이전트가 복잡한 논리를 추적하거나 가정을 검증하거나 엣지 케이스를 다뤄야 할 때 사용합니다(예: 리뷰어나 보안 중심 에이전트).
- **`medium`**: 대부분 에이전트에 대한 균형 잡힌 기본값입니다.
- **`low`**: 작업이 단순하고 속도가 가장 중요한 경우에 사용합니다.

추론 노력을 높이면 응답 시간과 토큰 소비가 증가하지만 복잡한 작업의 품질은 향상될 수 있습니다. 자세한 내용은 [Models](https://developers.openai.com/codex/models), [Config basics](https://developers.openai.com/codex/config-basic), [Configuration Reference](https://developers.openai.com/codex/config-reference)를 참조하세요.
